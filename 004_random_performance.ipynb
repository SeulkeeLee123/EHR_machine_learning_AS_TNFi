{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# You can modify file names and path to files as you need.\n",
    "path_to_data_file = 'data_file.txt'\n",
    "performance_file = 'random_hyperparameter_tuning.txt'\n",
    "n = 1000 # Number of dataset\n",
    "##################\n",
    "\n",
    "whole_data = [line.strip().split('\\t') for line in open(path_to_data_file)]\n",
    "del(whole_data[0])\n",
    "\n",
    "featDic = {}\n",
    "data_list_x = []\n",
    "data_list_y = []\n",
    "\n",
    "for line in whole_data:\n",
    "    featDic[line[0]] = list(map(float,line[1:11])) + list(map(int,line[11:13])) + list(map(float,line[13:15])) + list(map(int,line[15]))\n",
    "    data_list_x.append(featDic[line[0]][:-1])\n",
    "    data_list_y.append(featDic[line[0]][-1])\n",
    "    \n",
    "data_x = np.array(data_list_x)\n",
    "data_y = np.array(data_list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_floats(low, high, k=1):\n",
    "    result = []\n",
    "    seen = set()\n",
    "    for i in range(k):\n",
    "        x = random.uniform(low, high)\n",
    "        while x in seen:\n",
    "            x = random.uniform(low, high)\n",
    "        seen.add(x)\n",
    "        result.append(x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "\n",
    "stats = defaultdict(list)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    pred_random = np.array(sample_floats(0.0,1.0,k=n))\n",
    "    \n",
    "    fpr, tpr, threshold = metrics.roc_curve(data_y, pred_random)\n",
    "    random_acc = metrics.accuracy_score(data_y, pred_random.round())\n",
    "    random_roc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    precision_random, recall_random, thresholds = precision_recall_curve(data_y, pred_random)\n",
    "    random_f1 = f1_score(data_y, pred_random.round())\n",
    "\n",
    "    random_rp = metrics.auc(recall_random, precision_random)\n",
    "    \n",
    "    stats['acc'].append(random_acc)\n",
    "    stats['roc'].append(random_roc)\n",
    "    stats['f1'].append(random_f1)\n",
    "    stats['rp'].append(random_rp)\n",
    "    \n",
    "alpha=0.95\n",
    "p_l = ((1.0-alpha)/2) * 100\n",
    "p_u = (alpha + ((1.0 - alpha)/ 2.0)) * 100\n",
    "\n",
    "mean_perf = dict()\n",
    "lower = dict()\n",
    "upper = dict()\n",
    "\n",
    "result = open(performance_file, 'w')\n",
    "\n",
    "perf_list = ['acc', 'roc', 'f1', 'rp']\n",
    "for perf in perf_list:\n",
    "    mean_perf[perf] = sum(stats[perf]) / len(stats[perf])\n",
    "    lower[perf] = max(0.0, np.percentile(stats[perf],p_l))\n",
    "    upper[perf] = min(1.0, np.percentile(stats[perf],p_u))\n",
    "\n",
    "    result.write('\\t'.join([perf, str(mean_perf[perf]), str(lower[perf]), str(upper[perf])]) + '\\n')\n",
    "    \n",
    "result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

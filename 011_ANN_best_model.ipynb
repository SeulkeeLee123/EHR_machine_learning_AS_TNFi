{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import optimizers\n",
    "import sklearn.metrics as metrics\n",
    "from numpy import interp\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# You have to modify file names and path to files as you need.\n",
    "path_to_data_file = 'PATH/TO/DATA/FILE'\n",
    "test_index_file = 'PATH/TO/TEST/INDEX'\n",
    "train_index_file = 'PATH/TO/TRAIN/INDEX'\n",
    "saved_model_folder = 'PATH/TO/MODEL/SAVED'\n",
    "performance_file = 'PATH/TO/PERFORMANCE/FILE'\n",
    "##################\n",
    "\n",
    "# You have to modify this part by your own hyperparameter set.\n",
    "n_nodes = 60\n",
    "n_layers = 5\n",
    "lr = 0.00003\n",
    "n_batch = 20\n",
    "n_epochs = 200\n",
    "n_cv = 3\n",
    "\n",
    "seed = random.randint(0,10000)\n",
    "\n",
    "whole_data = [line.strip().split('\\t') for line in open(path_to_data_file)]\n",
    "del(whole_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featDic= {}\n",
    "data_list_x = []\n",
    "data_list_y = []\n",
    "\n",
    "for line in whole_data:\n",
    "    featDic[line[0]] = list(map(float,line[1:11])) + list(map(int,line[11:13])) + list(map(float,line[13:15])) + list(map(int,line[15]))\n",
    "    data_list_x.append(featDic[line[0]][:-1])\n",
    "    data_list_y.append(featDic[line[0]][-1])\n",
    "\n",
    "data_x_bf_st = np.array(data_list_x)\n",
    "data_x = (data_x_bf_st - np.mean(data_x_bf_st, axis=0))/np.std(data_x_bf_st, axis=0)\n",
    "data_y = np.array(data_list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_cv, shuffle=True, random_state=seed)\n",
    "\n",
    "tprs = []\n",
    "accs = []\n",
    "ROC_aucs = []\n",
    "f1s = []\n",
    "RP_aucs = []\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in cv.split(data_x, data_y):\n",
    "\n",
    "    with open(test_index_file, 'a') as index_file:\n",
    "        index_file.write('%i_%i\\t' % (seed, i + 1))\n",
    "        index_file.write(','.join(str(x) for x in test) + '\\n')\n",
    "    with open(train_index_file, 'a') as train_index_file:\n",
    "        train_index_file.write('%i_%i\\t' % (seed, i + 1))\n",
    "        train_index_file.write(','.join(str(x) for x in train) + '\\n')\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    for i_layer in range(n_layers):\n",
    "        model.add(keras.layers.Dense(n_nodes, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    Adam=optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer=Adam,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.fit(data_x[train], data_y[train], batch_size=n_batch, epochs=n_epochs)\n",
    "\n",
    "    model.save(saved_model_folder + '/%i_%i_noca.h5' % (seed, i + 1))\n",
    "    print('model saved')\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(data_x[test], data_y[test])\n",
    "    predictions = model.predict(data_x[test])\n",
    "\n",
    "    accs.append(test_acc)\n",
    "    \n",
    "    fpr, tpr, threshold = metrics.roc_curve(data_y[test], predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    ROC_aucs.append(roc_auc)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(data_y[test], predictions)\n",
    "    f1 = f1_score(data_y[test], predictions.round())\n",
    "    f1s.append(f1)\n",
    "    rp_auc = metrics.auc(recall, precision)\n",
    "    RP_aucs.append(rp_auc)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = metrics.auc(mean_fpr, mean_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(performance_file, 'a') as perf_file:\n",
    "    perf_file.write('\\t'.join([str(seed), str(sum(accs) / 3), '\\t'.join(str(x) for x in accs), \n",
    "                               str(mean_auc), '\\t'.join(str(x) for x in ROC_aucs),\n",
    "                               str(sum(f1s)/3), '\\t'.join(str(x) for x in f1s),\n",
    "                               str(sum(RP_aucs) / 3), '\\t'.join(str(x) for x in RP_aucs)]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
